{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "One Hot"
      ],
      "metadata": {
        "id": "1R3hlRKoTKnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample data\n",
        "words = [\"cat\", \"dog\", \"fish\", \"dog\", \"cat\"]\n",
        "\n",
        "# One-hot encoding using LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "encoded_labels = encoder.fit_transform(words)\n",
        "\n",
        "# Create one-hot vectors\n",
        "one_hot_vectors = np.zeros((len(words), len(set(words))))\n",
        "for i, label in enumerate(encoded_labels):\n",
        "    one_hot_vectors[i][label] = 1\n",
        "\n",
        "print(\"One-Hot Encoding:\\n\", one_hot_vectors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdYsaOtyTOV7",
        "outputId": "0ab94c74-0fc5-4127-a6f1-043734a33fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-Hot Encoding:\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag Of Words"
      ],
      "metadata": {
        "id": "XNSvzrPXTcR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample data\n",
        "documents = [\"I love programming\", \"Python is awesome\", \"I love Python programming\", \"Python is love\"]\n",
        "\n",
        "# Create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the documents\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Convert the sparse matrix to a dense array\n",
        "print(\"Bag of Words (BoW) with CountVectorizer:\\n\", X.toarray())\n",
        "\n",
        "# Display the feature names (vocabulary)\n",
        "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejy8BhJ7Tf-i",
        "outputId": "c78c3348-85cd-413a-e466-2184313c003e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words (BoW) with CountVectorizer:\n",
            " [[0 0 1 1 0]\n",
            " [1 1 0 0 1]\n",
            " [0 0 1 1 1]\n",
            " [0 1 1 0 1]]\n",
            "Vocabulary: ['awesome' 'is' 'love' 'programming' 'python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample data\n",
        "documents = [\"I love programming\", \"Python is awesome\", \"I love Python programming\"]\n",
        "\n",
        "# Create TfidfVectorizer object\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the documents\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Convert the sparse matrix to a dense array\n",
        "print(\"TF-IDF Matrix:\\n\", X_tfidf.toarray())\n",
        "\n",
        "# Display the feature names (vocabulary)\n",
        "print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHFedLYPTxma",
        "outputId": "abd679b8-46d0-41c9-9960-fe806b6edcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix:\n",
            " [[0.         0.         0.70710678 0.70710678 0.        ]\n",
            " [0.62276601 0.62276601 0.         0.         0.4736296 ]\n",
            " [0.         0.         0.57735027 0.57735027 0.57735027]]\n",
            "Vocabulary: ['awesome' 'is' 'love' 'programming' 'python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Sample data (list of tokenized sentences)\n",
        "sentences = [[\"i\", \"love\", \"programming\"], [\"python\", \"is\", \"awesome\"], [\"i\", \"love\", \"python\"]]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model_w2v = Word2Vec(sentences, vector_size=50, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get the vector for a specific word\n",
        "vector_cat = model_w2v.wv[\"python\"]\n",
        "print(\"Word2Vec - Vector for 'python':\\n\", vector_cat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYgGl1uyT37i",
        "outputId": "8e58499c-6815-4abf-ad51-78ad7b54a970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec - Vector for 'python':\n",
            " [-1.0724545e-03  4.7286271e-04  1.0206699e-02  1.8018546e-02\n",
            " -1.8605899e-02 -1.4233618e-02  1.2917745e-02  1.7945977e-02\n",
            " -1.0030856e-02 -7.5267432e-03  1.4761009e-02 -3.0669428e-03\n",
            " -9.0732267e-03  1.3108104e-02 -9.7203208e-03 -3.6320353e-03\n",
            "  5.7531595e-03  1.9837476e-03 -1.6570430e-02 -1.8897636e-02\n",
            "  1.4623532e-02  1.0140524e-02  1.3515387e-02  1.5257311e-03\n",
            "  1.2701781e-02 -6.8107317e-03 -1.8928028e-03  1.1537147e-02\n",
            " -1.5043275e-02 -7.8722071e-03 -1.5023164e-02 -1.8600845e-03\n",
            "  1.9076237e-02 -1.4638334e-02 -4.6675373e-03 -3.8754821e-03\n",
            "  1.6154874e-02 -1.1861792e-02  9.0324880e-05 -9.5074680e-03\n",
            " -1.9207101e-02  1.0014586e-02 -1.7519170e-02 -8.7836506e-03\n",
            " -7.0199967e-05 -5.9236289e-04 -1.5322480e-02  1.9229487e-02\n",
            "  9.9641159e-03  1.8466286e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load pre-trained GloVe model\n",
        "def load_glove_model(glove_file):\n",
        "    model = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.split()\n",
        "            word = parts[0]\n",
        "            vector = np.array(parts[1:], dtype=np.float32)\n",
        "            model[word] = vector\n",
        "    return model\n",
        "\n",
        "# Example GloVe file (replace with the path to your local GloVe file)\n",
        "glove_model = load_glove_model(\"glove.6B.50d.txt\")  # 50D GloVe vectors\n",
        "\n",
        "# Get the vector for a specific word\n",
        "vector_glove = glove_model[\"python\"]\n",
        "print(\"GloVe - Vector for 'python':\\n\", vector_glove)\n"
      ],
      "metadata": {
        "id": "PpHeskqlWLt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "# Example sentences for FastText training\n",
        "sentences = [[\"i\", \"love\", \"programming\"], [\"python\", \"is\", \"awesome\"], [\"i\", \"love\", \"python\"]]\n",
        "\n",
        "# Train a FastText model\n",
        "model_ft = FastText(sentences, vector_size=50, window=3, min_count=1, workers=4)\n",
        "\n",
        "# Get the vector for a specific word\n",
        "vector_ft = model_ft.wv[\"python\"]\n",
        "print(\"FastText - Vector for 'python':\\n\", vector_ft)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWR-31GMWXOD",
        "outputId": "2d9abb20-e4f3-4199-e2d4-e8c31aad923c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText - Vector for 'python':\n",
            " [ 0.00767598  0.00292498 -0.00391118 -0.0019751  -0.00052945  0.00138819\n",
            "  0.00105093  0.00681139 -0.0019958  -0.00189362 -0.00215858  0.00351798\n",
            " -0.00101528 -0.00108583  0.00057213  0.00188714  0.004025    0.00218857\n",
            "  0.00135858 -0.0025631   0.000346   -0.00030462 -0.00225894 -0.00175163\n",
            "  0.00550426  0.00148931 -0.00095485  0.00230207 -0.00182532 -0.00287812\n",
            " -0.00570289  0.00406225 -0.00442473 -0.00068925 -0.00019111  0.00309115\n",
            " -0.00348415  0.00106954 -0.00219935 -0.00321007  0.00251087 -0.00073791\n",
            " -0.00128885  0.00094972  0.00122982  0.00244141 -0.00100991  0.00203276\n",
            "  0.00140259  0.00434942]\n"
          ]
        }
      ]
    }
  ]
}